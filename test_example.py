import asyncio
from genlm.backend import load_model_by_name
from genlm.bytes.byte_lm.beam import ByteBeamState, BeamParams


async def demo_auto_eos():
    print("DEMO: Auto-EOS Detection")
    print("=" * 50)

    model = load_model_by_name("gpt2")

    # Create beam with auto-EOS enabled (default)
    params = BeamParams(K=5, prune_threshold=0.05, verbose=True, auto_eos=True)
    beam = await ByteBeamState.initial(model, params)

    # The auto detection, should find gpt2's EOS token
    print(
        f"Auto-detected EOS tokens in trie: {getattr(beam.states[0].trie.trie, 'eos_tokens', 'None')}"
    )

    # Test prefill + generation
    context = b"Once upon a time"
    beam = await beam.prefill(context)

    print(f"\nAfter prefill with: {context}")
    print(f"Beam state: {len(beam.states)} active states")

    # Generate a few bytes to see EOS in action
    for i in range(10):
        logp_next = await beam.logp_next()
        probs = logp_next.materialize()

        # Check if EOS (byte 257) has logp
        eos_prob = probs.get(257, 0.0)
        print(f"Step {i + 1}: EOS logp = {eos_prob:.6f}")

        # Take the most likely next byte
        if probs:
            valid_bytes = [k for k in probs.keys() if k is not None]
            if valid_bytes:
                next_byte = max(valid_bytes, key=lambda x: probs[x])
                beam = await (beam.prune() << next_byte)

                if next_byte == 257:
                    print("EOS generated - terminating!")
                    break
                else:
                    print(
                        f"Generated byte: {next_byte} ({chr(next_byte) if 32 <= next_byte <= 126 else 'non-printable'})"
                    )
            else:
                print("No valid bytes available (all keys are None)")
                break
        else:
            print("No valid bytes available (empty probs)")
            break

    await beam.cleanup()
    print()


async def demo_manual_eos():
    print("DEMO: Manual EOS Configuration")
    print("=" * 50)

    model = load_model_by_name("gpt2")

    # Configure specific EOS tokens manually
    eos_tokens = {b".", b"!", b"?"}  # Punctuation as EOS
    params = BeamParams(
        K=3, prune_threshold=0.1, verbose=True, eos_tokens=eos_tokens, auto_eos=False
    )
    beam = await ByteBeamState.initial(model, params)

    print(f"Manual EOS tokens: {eos_tokens}")

    context = b"The quick brown fox jumps"
    beam = await beam.prefill(context)

    print(f"\nAfter prefill with: {context}")

    # Generate and look for natural sentence ending
    for i in range(8):
        logp_next = await beam.logp_next()
        probs = logp_next.materialize()

        eos_prob = probs.get(257, 0.0)
        print(f"Step {i + 1}: EOS logp = {eos_prob:.6f}")

        if probs:
            valid_bytes = [k for k in probs.keys() if k is not None]
            if valid_bytes:
                next_byte = max(valid_bytes, key=lambda x: probs[x])
                beam = await (beam.prune() << next_byte)

                if next_byte == 257:
                    print("EOS generated - sentence complete!")
                    break
                else:
                    print(
                        f"Generated: {chr(next_byte) if 32 <= next_byte <= 126 else f'byte({next_byte})'}"
                    )
            else:
                print("No valid bytes available (all keys are None)")
                break
        else:
            print("No valid bytes available (empty probs)")
            break

    await beam.cleanup()
    print()


async def demo_no_eos():
    print("DEMO: EOS Disabled")
    print("=" * 50)

    model = load_model_by_name("gpt2")

    # Disable both auto and manual EOS
    params = BeamParams(
        K=3, prune_threshold=0.1, verbose=True, auto_eos=False, eos_tokens=set()
    )
    beam = await ByteBeamState.initial(model, params)

    print("EOS functionality disabled")

    # Test generation: should never terminate on EOS
    context = b"Hello world"
    beam = await beam.prefill(context)

    for i in range(5):
        logp_next = await beam.logp_next()
        probs = logp_next.materialize()

        # EOS should have -inf logp
        eos_prob = probs.get(257, 0.0)
        print(f"Step {i + 1}: EOS logp = {eos_prob:.6f} (should be -inf)")

        if probs:
            # Filter out None keys and get valid bytes
            valid_bytes = [k for k in probs.keys() if k is not None]
            if valid_bytes:
                next_byte = max(valid_bytes, key=lambda x: probs[x])
                beam = await (beam.prune() << next_byte)
                print(
                    f"Generated: {chr(next_byte) if 32 <= next_byte <= 126 else f'byte({next_byte})'}"
                )
            else:
                print("No valid bytes available (all keys are None)")
                break
        else:
            print("No valid bytes available (empty probs)")
            break

    await beam.cleanup()
    print()


async def demo_combined_eos():
    print("DEMO: Combined Auto + Manual EOS")
    print("=" * 50)

    model = load_model_by_name("gpt2")

    # Combine auto-detection with manual EOS tokens
    manual_eos = {b".", b"!", b"?", b"\n\n"}  # Punctuation + paragraph breaks
    params = BeamParams(
        K=3,
        auto_eos=True,  # Auto-detect tokenizer's EOS
        eos_tokens=manual_eos,  # Plus manual EOS tokens
        verbose=True,  # Show what gets detected
    )

    beam = await ByteBeamState.initial(model, params)

    # Check what EOS tokens were configured
    configured_eos = getattr(beam.states[0].trie.trie, "eos_tokens", set())
    print(f"Final EOS tokens configured: {configured_eos}")
    print(
        f"Should include both auto-detected '<|endoftext|>' and manual tokens {manual_eos}"
    )

    # Test with context that could trigger multiple EOS types
    context = b"This is a test sentence"
    beam = await beam.prefill(context)

    print(f"\nAfter prefill with: {context}")

    # Generate and check EOS probabilities
    for i in range(8):
        logp_next = await beam.logp_next()
        probs = logp_next.materialize()

        eos_prob = probs.get(257, 0.0)
        print(f"Step {i + 1}: Combined EOS probability = {eos_prob:.6f}")

        if probs:
            valid_bytes = [k for k in probs.keys() if k is not None]
            if valid_bytes:
                next_byte = max(valid_bytes, key=lambda x: probs[x])

                if next_byte == 257:
                    print(
                        "Combined EOS generated - could be from tokenizer or manual tokens!"
                    )
                    break
                else:
                    beam = await (beam.prune() << next_byte)
                    print(
                        f"Generated: {chr(next_byte) if 32 <= next_byte <= 126 else f'byte({next_byte})'}"
                    )
            else:
                print("No valid bytes available")
                break
        else:
            print("No valid bytes available")
            break

    await beam.cleanup()
    print()


async def main():
    print("EOS Functionality Demo")

    try:
        await demo_auto_eos()
        await demo_manual_eos()
        await demo_no_eos()
        await demo_combined_eos()

        print("âœ… All demos completed successfully!")

    except Exception as e:
        print(f"Demo failed: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
